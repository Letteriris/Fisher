{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、作业要求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本要求：\n",
    "● 利用numpy实现Fisher判别\n",
    "● 对比sklearn的结果（应该完全一致）\n",
    "● 数据要求：与神经网络一致\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "from numpy.linalg import pinv, eig\n",
    "from scipy.linalg import orth\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "class MyLinearDiscriminantAnalysis(object):\n",
    "    def __init__(self, n_components=None, n_classes=None,\n",
    "                 predict_reduction=True, eps=0.001, random_state=None,\n",
    "                 covariance_type='spherical'):\n",
    "        self.n_components = n_components\n",
    "        self.n_classes = n_classes\n",
    "        self.predict_reduction = predict_reduction\n",
    "        self.eps = eps\n",
    "        self.random_state = random_state\n",
    "        self.covariance_type = covariance_type\n",
    "        self.mu_ = None\n",
    "        self.mu_c_ = None\n",
    "        self.S_within_ = None\n",
    "        self.S_between_ = None\n",
    "        self.W_ = None\n",
    "        self.W_inverse_ = None\n",
    "        self.eig_pairs_ = None\n",
    "        self.predictor_ = None\n",
    "        self.clusters_ = None\n",
    "        self.dimensionality_ = None\n",
    "        # Random seed:\n",
    "        np.random.seed(random_state)\n",
    "        random.seed(random_state)\n",
    "\n",
    "    def fit(self, X, y=None, n_clusters=None, min_clusters=2, max_clusters=40,class_clustering=True, verbose=False):\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        assert 0 < min_clusters <= max_clusters < n_samples * n_features\n",
    "        assert 0 <= self.eps\n",
    "\n",
    "        if y is None:\n",
    "            self.clusters_ = self._clustering(X=X, min_clusters=min_clusters,\n",
    "                                              max_clusters=max_clusters,\n",
    "                                              n_clusters=n_clusters,\n",
    "                                              verbose=verbose)\n",
    "        elif class_clustering:\n",
    "            self.clusters_ = - np.ones(y.shape, dtype=int)\n",
    "            for target in np.unique(y):\n",
    "                y_ = self._clustering(X=X[y == target], y=target,\n",
    "                                      min_clusters=min_clusters,\n",
    "                                      max_clusters=max_clusters,\n",
    "                                      n_clusters=n_clusters,\n",
    "                                      verbose=verbose)\n",
    "                y_ += np.max(self.clusters_) + 1\n",
    "                self.clusters_[y == target] = y_\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Targets were provided: using the labeled data and \"\n",
    "                      \"intra-class clustering.\\n\")\n",
    "        else:\n",
    "            self.clusters_ = y\n",
    "            if verbose:\n",
    "                print(\"Targets were provided: using the labeled data.\\n\")\n",
    "\n",
    "        self.mu_, self.mu_c_ = self._means(X=X, y=self.clusters_,\n",
    "                                           verbose=verbose)\n",
    "\n",
    "        N_c, self.S_within_ = self._scatter_within(X=X, y=self.clusters_,\n",
    "                                                   mu_c=self.mu_c_,\n",
    "                                                   verbose=verbose)\n",
    "\n",
    "        self.S_between_ = self._scatter_between(mu=self.mu_, mu_c=self.mu_c_,\n",
    "                                                N_c=N_c, verbose=verbose)\n",
    "\n",
    "        self.eig_pairs_ = self._eig_pairs(S_within=self.S_within_,\n",
    "                                          S_between=self.S_between_)\n",
    "\n",
    "        P = self._filter_eig_pairs(eig_pairs=self.eig_pairs_, eps=self.eps,\n",
    "                                   verbose=verbose)\n",
    "\n",
    "        self.W_ = self._fill_rank(P=P, verbose=verbose)\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_new = X @ self.W_\n",
    "\n",
    "        if self.n_components is not None:\n",
    "            n_features = X.shape[1]\n",
    "            assert 0 < self.n_components < n_features\n",
    "\n",
    "            if self.predict_reduction:\n",
    "                self.predictor_ = LinearRegression()\n",
    "                self.predictor_.fit(X_new[:, :self.n_components], X)\n",
    "            X_new = X_new[:, :self.n_components]\n",
    "\n",
    "        return X_new\n",
    "\n",
    "    def fit_transform(self, X, y=None, n_clusters=None,min_clusters=2, max_clusters=40,class_clustering=True,verbose=False):\n",
    "        self.fit(X=X, y=y, n_clusters=n_clusters,\n",
    "                 min_clusters=min_clusters,\n",
    "                 max_clusters=max_clusters,\n",
    "                 class_clustering=class_clustering,\n",
    "                 verbose=verbose)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def inverse_transform(self, X, predict_reduction=True, verbose=False):\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if self.W_inverse_ is None:\n",
    "            self.W_inverse_ = pinv(self.W_)\n",
    "\n",
    "        if n_features != self.W_.shape[1]:\n",
    "            assert n_features == self.n_components\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Reverse tranformation after dimensionality reduction \"\n",
    "                      f\"may yield unexpected results: \"\n",
    "                      f\"{n_features} dim. expanded to {self.W_.shape[1]} dim.\")\n",
    "\n",
    "            if self.predict_reduction and predict_reduction:\n",
    "                return self.predictor_.predict(X)\n",
    "            else:\n",
    "                mean = self.mu_.reshape(1, -1) @ self.W_\n",
    "                X_ = np.repeat(mean.reshape(1, -1), n_samples, 0)\n",
    "                X_[:, :n_features] = X[:, :n_features]\n",
    "\n",
    "            X = X_\n",
    "\n",
    "        return X @ self.W_inverse_\n",
    "\n",
    "    def _clustering(self, X, min_clusters, max_clusters, n_clusters=None,y=None, verbose=False):\n",
    "        n_samples = X.shape[0]\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"No target is provided: using unsupervised clustering.\\n\")\n",
    "\n",
    "        if self.n_classes is not None and y is None:\n",
    "            assert 0 < self.n_classes < n_samples * n_features\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Using the provided number of classes \"\n",
    "                      f\"({self.n_classes}) for unsupervised clustering.\\n\")\n",
    "            model = GaussianMixture(self.n_classes, covariance_type='full',\n",
    "                                    random_state=self.random_state).fit(X)\n",
    "        else:\n",
    "            if verbose:\n",
    "                if n_clusters is not None:\n",
    "                    min_clusters = max_clusters = n_clusters\n",
    "                    print(f\"Using the provided number of clusters \"\n",
    "                          f\"({n_clusters}) for unsupervised clustering.\\n\")\n",
    "                elif y is not None:\n",
    "                    print(f\"Searching for an optimal number of clusters within\"\n",
    "                          f\" class {y} for values between {min_clusters} and \"\n",
    "                          f\"{max_clusters}...\\n\")\n",
    "                else:\n",
    "                    print(\"Predicting the classes from the clusters...\\n\")\n",
    "                    print(f\"Searching for an optimal number of clusters \"\n",
    "                          f\"between {min_clusters} and {max_clusters}...\\n\")\n",
    "\n",
    "            range_n = np.arange(min_clusters, max_clusters + 1)\n",
    "            models = []\n",
    "            for n in range_n:\n",
    "                gmm = GaussianMixture(n, covariance_type=self.covariance_type,\n",
    "                                      random_state=self.random_state).fit(X)\n",
    "                models.append(gmm)\n",
    "                if verbose:\n",
    "                    print(f\"{n} clusters: \"\n",
    "                          f\"\\tAIC: {gmm.aic(X):.3f}, \"\n",
    "                          f\"\\tBIC: {gmm.bic(X):.3f}  \")\n",
    "            index = np.argmin(np.array([m.aic(X) for m in models]))\n",
    "            model = models[index]\n",
    "            self.n_classes = index + min_clusters\n",
    "            if verbose and n_clusters is None:\n",
    "                a = f\" for class {y}\" if y is not None else \"\"\n",
    "                print(f\"Optimal number of clusters{a} found: \"\n",
    "                      f\"{self.n_classes}\\n\")\n",
    "\n",
    "        return model.predict(X)\n",
    "\n",
    "    @staticmethod\n",
    "    def _means(X, y, verbose=False):\n",
    "        n_features = X.shape[1]\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "        mu = np.mean(X, axis=0).reshape(1, -1)\n",
    "        if verbose:\n",
    "            print(f\"Mu:\\n{mu}\\n\")\n",
    "\n",
    "        mu_c = np.zeros((n_classes, n_features))\n",
    "        for i, target in enumerate(np.unique(y)):\n",
    "            mu_c[i] = np.mean(X[y == target], axis=0)\n",
    "            if verbose:\n",
    "                print(f\"Mu_c[{i}]:\\n{mu_c[i]}\\n\")\n",
    "\n",
    "        return mu, mu_c\n",
    "\n",
    "    @staticmethod\n",
    "    def _scatter_within(X, y, mu_c, verbose=False):\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "        data = []\n",
    "        N_c = np.zeros(n_classes)\n",
    "        for i, target in enumerate(np.unique(y)):\n",
    "            delta = X[y == target] - mu_c[i]\n",
    "            data.append(delta.T @ delta)\n",
    "            N_c[i] = np.sum(y == target)\n",
    "\n",
    "        S_within = np.sum(data, axis=0)\n",
    "        if verbose:\n",
    "            print(f\"S_intra:\\n{S_within}\\n\")\n",
    "\n",
    "        return N_c, S_within\n",
    "\n",
    "    @staticmethod\n",
    "    def _scatter_between(mu, mu_c, N_c, verbose=False):\n",
    "        delta = np.array(mu_c - mu)\n",
    "        S_between = N_c * delta.T @ delta\n",
    "        if verbose:\n",
    "            print(f\"S_inter:\\n{S_between}\\n\")\n",
    "\n",
    "        return S_between\n",
    "\n",
    "    @staticmethod\n",
    "    def _eig_pairs(S_within, S_between):\n",
    "        A = pinv(S_within) @ S_between\n",
    "        eig_val, eig_vec = eig(A)\n",
    "        eig_val = np.abs(eig_val)\n",
    "\n",
    "        return sorted(zip(eig_val, eig_vec.T), key=lambda k: k[0],\n",
    "                      reverse=True)\n",
    "\n",
    "    def _filter_eig_pairs(self, eig_pairs, eps, verbose=False):\n",
    "        eig_vals, eig_vecs = zip(*eig_pairs)\n",
    "        total = sum(eig_vals)\n",
    "        eigenvectors = []\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Singular values:\")\n",
    "        for i, v in enumerate(eig_pairs):\n",
    "            if v[0] / total >= eps / 100:\n",
    "                verdict = 'Accepted'\n",
    "                eigenvectors.append(v[1])\n",
    "            else:\n",
    "                verdict = 'Rejected'\n",
    "            if verbose:\n",
    "                percentage = v[0] / total\n",
    "                eigenvalue = v[0]\n",
    "                print(f\"Singular value {i + 1:}: \"\n",
    "                      f\"\\t{percentage:<8.2%} \"\n",
    "                      f\"\\t{eigenvalue:<8.6f} \\t {verdict}\")\n",
    "        if verbose:\n",
    "            print()\n",
    "\n",
    "        self.dimensionality_ = len(eigenvectors)\n",
    "\n",
    "        return np.vstack(eigenvectors).T.real\n",
    "\n",
    "    @staticmethod\n",
    "    def _fill_rank(P, verbose=False):\n",
    "        n_features = P.shape[0]\n",
    "\n",
    "        while True:\n",
    "            W = randn(n_features, n_features)\n",
    "            W = orth(W)\n",
    "            W[:P.shape[0], :P.shape[1]] = P\n",
    "            if orth(W).shape == (n_features, n_features):\n",
    "                break\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"W:\\n{W}\\n\")\n",
    "\n",
    "        return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.62208741e-01 -1.10986194e-01  6.43303975e-02  1.83907311e-01\n",
      "  -1.53005051e-01 -1.57368237e-01  4.01472835e-01  6.93121652e-02\n",
      "  -6.52883630e-01 -4.78158438e-02 -1.08525509e-03 -2.29735242e-02\n",
      "  -1.20552058e+00 -3.42389223e-02 -1.54300807e-01 -7.77544587e-02\n",
      "   5.88824132e-02  1.14091928e-01  2.63931747e-01  5.70821244e-02]\n",
      " [ 1.03443923e-01 -2.00860438e-02  3.38658371e-01 -1.76872404e-01\n",
      "  -2.11760508e-01  4.75502912e-03 -3.85601175e-01 -4.91112340e-02\n",
      "   5.05596923e-01  9.47820013e-02  2.53815082e-01 -2.42088682e-01\n",
      "   8.21704333e-01  1.39189183e-01  1.94155797e-02  1.64083752e-01\n",
      "  -4.78974252e-02 -4.14699437e-02 -1.21318579e-01  1.79793647e-01]]\n",
      "(array([[ 0.18441398, -0.06644512,  0.1987511 ,  0.00712525, -0.18179523,\n",
      "        -0.07792784,  0.01580657,  0.0112847 , -0.08522816,  0.0220571 ,\n",
      "         0.12381591, -0.13033995, -0.21218037,  0.05074085, -0.06917978,\n",
      "         0.04074626,  0.00656029,  0.03786661,  0.07515909,  0.11721077]]), array([[ 2.62208741e-01, -1.10986194e-01,  6.43303975e-02,\n",
      "         1.83907311e-01, -1.53005051e-01, -1.57368237e-01,\n",
      "         4.01472835e-01,  6.93121652e-02, -6.52883630e-01,\n",
      "        -4.78158438e-02, -1.08525509e-03, -2.29735242e-02,\n",
      "        -1.20552058e+00, -3.42389223e-02, -1.54300807e-01,\n",
      "        -7.77544587e-02,  5.88824132e-02,  1.14091928e-01,\n",
      "         2.63931747e-01,  5.70821244e-02],\n",
      "       [ 1.03443923e-01, -2.00860438e-02,  3.38658371e-01,\n",
      "        -1.76872404e-01, -2.11760508e-01,  4.75502912e-03,\n",
      "        -3.85601175e-01, -4.91112340e-02,  5.05596923e-01,\n",
      "         9.47820013e-02,  2.53815082e-01, -2.42088682e-01,\n",
      "         8.21704333e-01,  1.39189183e-01,  1.94155797e-02,\n",
      "         1.64083752e-01, -4.78974252e-02, -4.14699437e-02,\n",
      "        -1.21318579e-01,  1.79793647e-01]]))\n",
      "[ 0.81098871 -0.17293789  0.68277297 -1.83173068  0.21541019  0.02901842\n",
      " -0.27382454 -0.15896247 -0.15165988 -1.75574922 -3.05260385 -0.27059388\n",
      "  0.46127675  1.38266028  0.19589973  0.46260245  1.01186445  0.48106932\n",
      " -0.79845489  0.49427022]\n",
      "[[ 1.04392654]\n",
      " [-0.74701173]\n",
      " [ 1.23573188]\n",
      " [ 2.45774922]\n",
      " [ 0.08255366]\n",
      " [ 0.96369591]\n",
      " [ 1.96837698]\n",
      " [ 1.18378288]\n",
      " [-0.09021824]\n",
      " [ 1.74878787]\n",
      " [-2.15594269]\n",
      " [-0.21881422]\n",
      " [ 1.70121432]\n",
      " [-1.85718348]\n",
      " [ 2.04012981]\n",
      " [ 2.72524572]\n",
      " [-0.9017422 ]\n",
      " [-0.42151569]\n",
      " [ 0.53820456]\n",
      " [-0.8271274 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Letter\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "X,Y = make_classification(n_classes=2)\n",
    "mylda = MyLinearDiscriminantAnalysis()\n",
    "sklda = LinearDiscriminantAnalysis()\n",
    "mylda.fit(X,Y)\n",
    "sklda.fit(X,Y)\n",
    "print(sklda.means_)\n",
    "print(mylda._means(X,Y))\n",
    "print(mylda.transform(X[1]))\n",
    "print(sklda.transform(X[1].reshape(-1,1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
